# STAT5243-project3
project3 - A/B test
ä¸‹é¢æ˜¯ä¸ºä½ ä¸¤ä¸ªæ–‡ä»¶å¤¹ç¼–å†™çš„è¯¦ç»† README æ–‡ä»¶ï¼Œçªå‡ºä½ è¿›è¡Œçš„ A/B æµ‹è¯•å®éªŒå’Œæ—¥å¿—è®°å½•æ–¹å¼ã€‚

---

### ğŸ“ `STAT5243_project_2`
**Description:**  
è¿™æ˜¯ä¸€ä¸ªåŸºäº [Python Shiny](https://shiny.posit.co/py/) å®ç°çš„äº¤äº’å¼æ•°æ®æ¸…æ´—ä¸ç‰¹å¾å·¥ç¨‹å¹³å°ï¼Œä¸»è¦ç”¨äºæ‰§è¡Œ A/B æµ‹è¯•å®éªŒã€‚å®éªŒæ ¸å¿ƒç›®æ ‡æ˜¯æµ‹è¯•æç¤ºæ–‡æœ¬é¢œè‰²ï¼ˆå¦‚çº¢è‰² vs é»‘è‰²ï¼‰å¯¹ç”¨æˆ·è¡Œä¸ºçš„å½±å“ã€‚

**ğŸ”¬ A/B Testing Objective:**  
æˆ‘ä»¬å°† Note çš„æç¤ºé¢œè‰²ï¼ˆä¾‹å¦‚ `çº¢è‰²` vs `é»‘è‰²`ï¼‰ä½œä¸ºå®éªŒå˜é‡ï¼Œéšæœºåˆ†é…ç”¨æˆ·è‡³ A/B ä¸¤ç»„ï¼š

- **Group A:** æ˜¾ç¤ºçº¢è‰²æç¤ºæ–‡æœ¬ï¼ˆé»˜è®¤æ ·å¼ï¼‰
- **Group B:** æ˜¾ç¤ºé»‘è‰²æç¤ºæ–‡æœ¬ï¼ˆå»å¼ºè°ƒï¼‰

**ğŸ¯ æµ‹é‡æŒ‡æ ‡ï¼š**

æ¯ä¸ªç”¨æˆ·ä¼šè¯é€šè¿‡æ—¥å¿—ç³»ç»Ÿè®°å½•ä»¥ä¸‹æ“ä½œè¡Œä¸ºæŒ‡æ ‡ï¼š

- `apply_fe_button_clicked_count`: åº”ç”¨äº†ç‰¹å¾å·¥ç¨‹çš„ç‚¹å‡»æ¬¡æ•°
- `apply_fe_button_error_count`: ç‚¹å‡»æ—¶å‡ºé”™æ¬¡æ•°
- `revert_button_clicked_count`: æ’¤é”€ä¿®æ”¹ç‚¹å‡»æ¬¡æ•°
- `download_button_clicked_count`: ä¸‹è½½æ•°æ®çš„ç‚¹å‡»æ¬¡æ•°
- `download_button_clicked_time`: ä¸‹è½½æŒ‰é’®é¦–æ¬¡ç‚¹å‡»æ—¶é—´
- `*_clicked_rate`: æ¯ä¸ªæŒ‰é’®ç‚¹å‡»æ¬¡æ•° / æ€»ä¼šè¯æ—¶é—´
- `session_start_time`, `session_end_time`, `total_session_time`

æ•°æ®ä¼šè¢«å†™å…¥æœ¬åœ° CSV æ–‡ä»¶ `session_log.csv`ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ HTTP POST å‘é€è‡³æ—¥å¿—æœåŠ¡å™¨ã€‚

**ğŸ§© åŠŸèƒ½æ¨¡å—ï¼š**

- æ•°æ®æ–‡ä»¶ä¸Šä¼ ä¸å†…ç½®æ•°æ®åŠ è½½ï¼ˆæ”¯æŒ CSV, Excel, JSON, RDS ç­‰ï¼‰
- å˜é‡é€‰æ‹©ä¸æ•°æ®æ¸…æ´—
- ç¼ºå¤±å€¼å¤„ç†ï¼ˆè½¬ä¸º NAã€å‡å€¼/ä¼—æ•°å¡«å……ã€åˆ—è¡¨åˆ é™¤ï¼‰
- ç‰¹å¾å·¥ç¨‹æ“ä½œï¼ˆå½’ä¸€åŒ–ã€ç‹¬çƒ­ç¼–ç ã€æ—¥æœŸè½¬å¤©æ•°ã€Box-Cox è½¬æ¢ï¼‰
- å¯è§†åŒ–ï¼ˆçº¿å›¾ã€æŸ±å›¾ã€æ•£ç‚¹å›¾ã€ç›´æ–¹å›¾ã€ç›¸å…³çƒ­åŠ›å›¾ï¼‰
- æ—¥å¿—ç³»ç»Ÿè‡ªåŠ¨è®°å½•ç”¨æˆ·è¡Œä¸ºæ•°æ®ç”¨äºå®éªŒè¯„ä¼°

---

### ğŸ“ `STAT5243_log_server`
**Description:**  
è¿™æ˜¯é…å¥—çš„ Flask æœåŠ¡å™¨ç«¯ï¼Œç”¨äºæ¥æ”¶å¹¶å­˜å‚¨å‰ç«¯ Shiny åº”ç”¨ä¸­å‘èµ·çš„æ—¥å¿—æ•°æ®ã€‚

**ğŸ”§ æŠ€æœ¯ç»†èŠ‚ï¼š**

- ä½¿ç”¨ Flask æä¾› `/log` è·¯ç”±æ¥æ”¶ JSON æ—¥å¿— POST è¯·æ±‚
- æ—¥å¿—å†…å®¹åŒ…æ‹¬ç”¨æˆ· IDã€åˆ†ç»„ã€æŒ‰é’®ç‚¹å‡»æ•°ã€ç‚¹å‡»æ—¶é—´ã€æ€»ä¼šè¯æ—¶é—´ç­‰
- æ‰€æœ‰æ—¥å¿—ç»Ÿä¸€å­˜å‚¨åœ¨ `server_log.csv` ä¸­

**ğŸš€ å¯åŠ¨æ–¹å¼ï¼š**

```bash
cd STAT5243_log_server
python log_server.py
```

å¯åŠ¨åå°†ç›‘å¬ `http://127.0.0.1:5000/log`ï¼Œå¹¶ç­‰å¾…æ¥è‡ªå‰ç«¯åº”ç”¨çš„æ—¥å¿—ä¸Šä¼ ã€‚

---

--------------------------------------------------------

Statistical Analysis - Nan Xiao

Summarization of the steps:
We've created a Python script for analyzing an AB test dataset comparing "red" and "gray" groups.
The script performs the following analysis for each metric:
Computes descriptive statistics for each group
Tests for normality to decide which statistical test to use
Performs either t-tests (for normal data) or Mann-Whitney U tests (for non-normal data)
Creates bar plots comparing the groups with significance indicators
Adds detailed statistics and test results on the plots
The script saves all plots to a dedicated directory (C:/Users/å‡¡æ›²/AB_Test_Results) and also attempts to display them in windows.
A summary CSV file with all statistical test results is also saved.

Summary of Analysis Results
Based on the analysis of the AB test data comparing "red" and "gray" groups, here are the key findings:
Clicked Rate: No statistically significant difference between red and gray groups (p=0.3584)
Clicked Count: Statistically significant difference (p=0.0211)
Gray group has higher clicked count (7.94 vs 6.81)
Gray interface performs 15.4% better in this metric
Session Time: No statistically significant difference (p=0.6929)
Error Count: Statistically significant difference (p<0.0001)
Red group has lower error count (0.47 vs 1.10)
Users are 80.3% less likely to make errors with the red interface
Error Rate: Statistically significant difference (p=0.0001)
Red group has lower error rate (0.0037 vs 0.0065)
Users show 54.9% lower error rate with the red interface
Overall Conclusion
The red interface appears to perform better overall, winning in 2 out of 3 significant metrics (error count and error rate). While the gray interface leads in clicked count, the red interface demonstrates superior performance in reducing errors.
The analysis shows that:
Users click more with the gray interface
Users make fewer errors with the red interface
Session time isn't significantly different between interfaces
Recommendation
Based on the analysis, the red interface would be the recommended choice if minimizing errors is the primary goal. However, if higher engagement (more clicks) is prioritized, the gray interface might be preferred.
All the plots, detailed statistics, and conclusions have been saved to C:/Users/å‡¡æ›²/AB_Test_Results/ for further reference.
